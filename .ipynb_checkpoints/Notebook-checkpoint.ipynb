{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining Group Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everyone knows that feeling when you are sitting hungry at home, while having no idea what you want to eat. Well, no more! Rather than staring uninspired at the item in your fridge, our NLPChef will help you decide what to do with them! Not only can this model generate original, realistic, and fun recipes, it can do so based on a list of ingredients you have available. Simply tell the model what you have in your fridge, and it will generate a recipe based on what you have available. Or if you don't feel like giving the model inputs yourself, some example recipes (with corresponding ingredient list) can be found in the AllRecipes.txt file\n",
    "\n",
    "This Text Mining project represents a unique approach to both NLP and Cooking; by Sergio Kazatzidis, Emilia Chammas, and Tim Holthuijsen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial model:\n",
    "When we started with this project, we had a very different modeling approach from our final version. In order to showcase our thought process, we start this analysis off by creating our initial recipe generation model from the pretrained GPT-2 model.\n",
    "\n",
    "with some help from [TowardsDataScience](https://towardsdatascience.com/text-generation-with-python-and-gpt-2-1fecbff1635b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "#Defining the model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "#Defining a context sequence\n",
    "sequence = 'Bake 5 eggs. Add them to the tomatoes. Boil the pasta.'\n",
    "#encoding input\n",
    "encoded = tokenizer.encode(sequence, return_tensors='pt')\n",
    "#Letting the model generate text based on the context\n",
    "output = model.generate(encoded, max_length=100, \n",
    "                        do_sample=True,\n",
    "                        temperature = 7.0,\n",
    "                        top_k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of this GPT-2 recipe generation is that by providing a sequence context string based on food and cooking, the language model will also generate a text related to this, which is often very close to a recipe. More sophisticated (and longer) iterations of this model have yielded relatively succesful recipes, one of which is saved in the /Recipes folder. \n",
    "\n",
    "GPT2's development can be found at: Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2018). Language Models are Unsupervised Multitask Learners. 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bake 5 eggs. Add them to the tomatoes. Boil the pasta. Cover and drain and add them in to another small serving.\n",
      "If the dough turns to greasy at the beginning. Then just knead all that liquid off so there will now remain some surface in the pasta dough for its purpose to continue folding (about half) when the bread hits the edge where that's it from where? Do I get the \"granny pin pie\"â€¦?<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "recipe = tokenizer.decode(output[0])\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this already provides relatively skillful recipes, they are not as skillful and customizable as we want. Specifically, we want to be able to train and customize our model based on a specific dataset. This gives more control in creating the model, and means that our cooking model will be trained on cooking data specifically, rather than GPT-2's more general background. It also means we can train our model in a way that it can take in a list of ingredients, and output a recipe based on those ingredients. Using our own data to train the model has the additional advantage that you can use Italian recipes to train your Italian NLP cooking book, and French recipes for your French cookbook. \n",
    "\n",
    "In order to start defining and training our own model, we first acquire a large amount of cooking data: 125164 recipes from [eightportions.com](https://eightportions.com/datasets/Recipes/#fn:1), by Ryan Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allr = open('recipes_raw_nosource_ar.json')\n",
    "epi = open('recipes_raw_nosource_epi.json')\n",
    "food = open('recipes_raw_nosource_fn.json')\n",
    "\n",
    "data1 = json.load(allr) #data 1 has a lot of the word ADVERTISEMENT\n",
    "data2 = json.load(epi) #data 2 looks good\n",
    "data3 = json.load(food) #this too\n",
    "\n",
    "#this load module loads the data into a dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammie Hamblet's Deviled Crab\n"
     ]
    }
   ],
   "source": [
    "#Example of the double dict structue of the .json files:\n",
    "print(data3[\"p3pKOD6jIHEcjf20CCXohP8uqkG5dGi\"]['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some help from [coursera](https://www.coursera.org/projects/generating-new-recipes-python)\n",
    "\n",
    "Our current recipes are in a dict of list of dict form, where the first dict contains the recipe code as key and the recipe as value, and the recipe value itself is a list of dicts in the shape [{title: value}, {ingredients: value}, {instructions:value}]. This is very annoying, and needs to be processed into a more workable format\n",
    "\n",
    "\n",
    "We start by defining a list of all the recipe codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first dataset contains 39802 recipes\n",
      "in total, we have 125164 recipes\n"
     ]
    }
   ],
   "source": [
    "#creating lists of keys\n",
    "codes1 = list(data1.keys())\n",
    "codes2 = list(data2.keys())\n",
    "codes3 = list(data3.keys())\n",
    "\n",
    "#and doing some data exploration\n",
    "NumRecipes = len(codes1) + len(codes2) + len(codes3)\n",
    "print('The first dataset contains', len(codes1), 'recipes')\n",
    "print('in total, we have', NumRecipes, 'recipes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Pandas dataframe\n",
    "The dict of lists of dicts format is suboptimal to work with for the modeling tasks we want to perform on it. Therefore, we convert everything nicely into our own pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data has been added to the lists succesfully!\n"
     ]
    }
   ],
   "source": [
    "#Create dataframe\n",
    "Data = pd.DataFrame()\n",
    "\n",
    "#initializing empty lists which we'll add to the dataframe\n",
    "Title = []\n",
    "Ingredients = []\n",
    "Instructions = []\n",
    "\n",
    "#a for-loop to put all the required data in the lists\n",
    "datasets = [data1, data2, data3]\n",
    "\n",
    "for data in datasets:\n",
    "    for _, val in data.items():\n",
    "        #We occasionally get keyerrors due to corrupted data\n",
    "        #so a try-except is added\n",
    "        try:\n",
    "            Title.append(val['title'])\n",
    "            Ingredients.append([\n",
    "                #And we remove the random ADVERTISEMENT clutter\n",
    "                ingredient.replace(\n",
    "                'ADVERTISEMENT', '') for ingredient in val['ingredients']])\n",
    "            Instructions.append([str(\n",
    "                val['instructions']).replace('ADVERTISEMENT','').replace('\\n', ' ')])                      \n",
    "        except:\n",
    "            continue\n",
    "\n",
    "#Quick check to see if it worked\n",
    "if len(Title) == len(Ingredients) and len(Title) == len(Instructions):\n",
    "    print(\"All data has been added to the lists succesfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During this transformation, 517 empty values have been removed\n",
      "We now have 124647 recipes\n"
     ]
    }
   ],
   "source": [
    "print(\"During this transformation,\", NumRecipes - len(Title), \"empty values have been removed\")\n",
    "print(\"We now have\", len(Title), \"recipes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier, we noticed that the first dataset contained a lot of random ADVERTISEMENT strings scattered around. This clutter has also been removed during the list comprehensions used above\n",
    "#### Adding data to dataframe\n",
    "We can now add all of the data we just created and finish up the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>Instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slow Cooker Chicken and Dumplings</td>\n",
       "      <td>[4 skinless, boneless chicken breast halves , ...</td>\n",
       "      <td>[Place the chicken, butter, soup, and onion in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Awesome Slow Cooker Pot Roast</td>\n",
       "      <td>[2 (10.75 ounce) cans condensed cream of mushr...</td>\n",
       "      <td>[In a slow cooker, mix cream of mushroom soup,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brown Sugar Meatloaf</td>\n",
       "      <td>[1/2 cup packed brown sugar , 1/2 cup ketchup ...</td>\n",
       "      <td>[Preheat oven to 350 degrees F (175 degrees C)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best Chocolate Chip Cookies</td>\n",
       "      <td>[1 cup butter, softened , 1 cup white sugar , ...</td>\n",
       "      <td>[Preheat oven to 350 degrees F (175 degrees C)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homemade Mac and Cheese Casserole</td>\n",
       "      <td>[8 ounces whole wheat rotini pasta , 3 cups fr...</td>\n",
       "      <td>[Preheat oven to 350 degrees F. Line a 2-quart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title  \\\n",
       "0  Slow Cooker Chicken and Dumplings   \n",
       "1      Awesome Slow Cooker Pot Roast   \n",
       "2               Brown Sugar Meatloaf   \n",
       "3        Best Chocolate Chip Cookies   \n",
       "4  Homemade Mac and Cheese Casserole   \n",
       "\n",
       "                                         Ingredients  \\\n",
       "0  [4 skinless, boneless chicken breast halves , ...   \n",
       "1  [2 (10.75 ounce) cans condensed cream of mushr...   \n",
       "2  [1/2 cup packed brown sugar , 1/2 cup ketchup ...   \n",
       "3  [1 cup butter, softened , 1 cup white sugar , ...   \n",
       "4  [8 ounces whole wheat rotini pasta , 3 cups fr...   \n",
       "\n",
       "                                        Instructions  \n",
       "0  [Place the chicken, butter, soup, and onion in...  \n",
       "1  [In a slow cooker, mix cream of mushroom soup,...  \n",
       "2  [Preheat oven to 350 degrees F (175 degrees C)...  \n",
       "3  [Preheat oven to 350 degrees F (175 degrees C)...  \n",
       "4  [Preheat oven to 350 degrees F. Line a 2-quart...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['Title'] = Title\n",
    "Data['Ingredients'] = Ingredients\n",
    "Data['Instructions'] = Instructions\n",
    "Data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains:  124647 values\n",
      "Mean Title Length is: 28.285253556042264 characters\n",
      "Mean Ingredient Length is: 10.565436793504858 ingredients\n",
      "Mean Instruction Length is: 989.6764944202428 characters\n"
     ]
    }
   ],
   "source": [
    "TitleLength = 0\n",
    "IngredientLength = 0\n",
    "InstructionLength = 0\n",
    "print(\"The dataset contains: \", len(Data), \"values\")\n",
    "for item in Data['Title']:\n",
    "    try:\n",
    "        TitleLength += len(item)\n",
    "    except:\n",
    "        continue\n",
    "for item in Data['Ingredients']:\n",
    "    IngredientLength += len(item)\n",
    "for item in Data['Instructions']:\n",
    "    InstructionLength += len(str(item)) - 2 \n",
    "print(\"Mean Title Length is:\", TitleLength/len(Data), \"characters\")\n",
    "print(\"Mean Ingredient Length is:\", IngredientLength/len(Data), \"ingredients\")\n",
    "print(\"Mean Instruction Length is:\", InstructionLength/len(Data), \"characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe Recognition\n",
    "With some help from: [TowardsDataScience](https://towardsdatascience.com/text-generation-with-python-and-gpt-2-1fecbff1635b), [StackExchange](https://datascience.stackexchange.com/questions/66394/how-does-bert-and-gpt-2-encoding-deal-with-token-such-as-startoftext-s), [Coursera](https://www.coursera.org/projects/generating-new-recipes-python) and [TowardsDataScience2](https://towardsdatascience.com/train-gpt-2-in-your-own-language-fc6ad4d60171)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data processed, we want to use the database's structure to train our own. Specifically, we want it to learn to recognize the following recipe structure:\n",
    "\n",
    "Ingredients: <br/> ingredient1 <br/> ingredient2 <br/> ingredient3 <br/><br/>\n",
    "Instructions: <br/> some text explaining instructions\n",
    "\n",
    "### Train/Test split\n",
    "In order to train our model towards this structure, we first create a training and validation set. We take 10% of the data as a traing set, and 50% as test set. We use such a small percentage for training since otherwise the dataset is simply too large to handle for the model training; and this model already takes hours to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define GPT-2 special end of document token\n",
    "special_token = ' <|endoftext|> '\n",
    "\n",
    "#Create a dataframe column that combines ingredients and instructions\n",
    "Data['combined'] = ' \\n Ingredients: \\n ' + Data.Ingredients.str.join(' \\n ') + \\\n",
    "' \\n Instructions: \\n ' +Data.Instructions.str.join(' \\n ') + special_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(Data['Title'])\n",
    "train = Data[:int(0.1*length)].combined.values\n",
    "test = Data[int(0.9*length):].combined.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12464"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write training and test data to a file\n",
    "with open('TrainingData.txt','w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(train))\n",
    "with open('TestData.txt','w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Now that we have the test and training datasets, we can train our model on this specific data. This task, however, is rather complicated: and cannot be performed solely in this notebook. Rather, we upload the TrainingData.txt to Google Colab. Then, we use the [run_lm_finetuning.py](https://github.com/alontalmor/pytorch-transformers/blob/master/examples/run_lm_finetuning.py) script from huggingface and define a bashscript run_experiments.sh to run it and to start training our model on the defined training data. run_lm_finetuning.py contains a number of errors, specifically with importing WarmupLinearSchedule from transformers. Therefore, we define our own WarmupLinearSchedule in the run_lm_finetuning.py, and use run_experiments.sh to train the custom model on our recently created training data. \n",
    "\n",
    "The trained model itself is unfortunately too large to upload to github, but the .sh and .py scripts used to train and create this custom model are attached with this assignment repository. 6 out of the 7 files of which our model consists do fit on github, and can be found in the /CustomModel directory. For the sake of inclusivity, our entire trained model is also available [here](https://1drv.ms/u/s!AlUeI82AcSLCo41KNfOUS5dTqT0tEQ?e=4Wyq21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the models trained on our dataset:\n",
    "tokenizer = AutoTokenizer.from_pretrained('CustomModel/')\n",
    "model = AutoModelForCausalLM.from_pretrained('CustomModel/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to test whether our trained model recognizes the Ingredients: etc. Instructions: etc. format.\n",
    "Therefore, we define a testsequence consisting of a list of ingredients from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsequence = test[100].split('Instructions')[0] + \" \\n Instructions:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Ingredients: \n",
      " 1/4 cup oil \n",
      " 6 medium onions, chopped \n",
      " 4 bell peppers, chopped \n",
      " 3 carrots, chopped \n",
      " 1 cup string beans, broken into pieces \n",
      " 3/4 cup peas \n",
      " 6 tomatoes, chopped \n",
      " 1/2 teaspoon black pepper \n",
      " 1 teaspoon dried thyme \n",
      " 4 cups medium grain brown rice, cooked (cold) \n",
      " 1/2 cup tomato paste \n",
      "  \n",
      " Instructions:\n"
     ]
    }
   ],
   "source": [
    "print(testsequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has the perfect format for our model to recognize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer.encode(testsequence, add_special_tokens = False,\n",
    "                           return_tensors='pt')\n",
    "\n",
    "modelgenerated = model.generate(input_ids = encoded, max_length = 700,\n",
    "                                temperature = 0.9,\n",
    "                                top_k = 20,\n",
    "                                do_sample = True,\n",
    "                               repetition_penalty = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For more information on hyperparameters:\n",
    "#model.generate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And Success!\n",
    "The model recognizes the ingredient list format, and generates a recipe based on the available ingredients!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Ingredients: \n",
      " 1/4 cup oil \n",
      " 6 medium onions, chopped \n",
      " 4 bell peppers, chopped \n",
      " 3 carrots, chopped \n",
      " 1 cup string beans, broken into pieces \n",
      " 3/4 cup peas \n",
      " 6 tomatoes, chopped \n",
      " 1/2 teaspoon black pepper \n",
      " 1 teaspoon dried thyme \n",
      " 4 cups medium grain brown rice, cooked (cold) \n",
      " 1/2 cup tomato paste \n",
      "  \n",
      " Instructions: \n",
      " Heat oil in a large frying pan. Add onions, garlic, and thyme. Add rice, cook, stir, and cook, stirring occasionally, about 10 minutes, or until rice is tender, about 1 hour. Add potatoes, 1 cup water, and cook, stirring occasionally, about 30 minutes. Add 1/2 cup rice. Stir in remaining 1/2 cup bean paste. Cook, stirring occasionally, until potato is tender, about 1 minute.  <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "for sequence in modelgenerated:\n",
    "    recipe = tokenizer.decode(sequence)\n",
    "    print(recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we want to create more recipes from our unused, test ingredient lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "#Generate recipes based on ingredients list and add them to a string\n",
    "AllRecipes = ''\n",
    "for i in range(10):\n",
    "    sequence = test[i].split('Instructions')[0] + \" \\n Instructions:\"\n",
    "    encoded = tokenizer.encode(sequence, add_special_tokens = False,\n",
    "                           return_tensors='pt')\n",
    "\n",
    "    modelgenerated = model.generate(input_ids = encoded, max_length = 700,\n",
    "                                temperature = 0.9,\n",
    "                                top_k = 20,\n",
    "                                do_sample = True,\n",
    "                               repetition_penalty = 1.0)\n",
    "    for recipe in modelgenerated:\n",
    "        text = tokenizer.decode(recipe)\n",
    "        AllRecipes = AllRecipes + text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Recipes\n",
    "And finally, we save all of the created recipes in a .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save generated recipes as .txt files:\n",
    "def save(recipe, filename):\n",
    "    text_file = open(filename, \"w\", encoding = 'utf8')\n",
    "    n = text_file.write(recipe)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(AllRecipes, 'Recipes/AllRecipes.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! We have now trained a custom NLP model that can generate recipes based on a list of ingredients. The next time thre's food in your fridge but you don't know what to eat, just ask the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contributors: Emilia, Sergio, Tim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Ingredients: \n",
      " 4 boneless chicken breasts (7 ounces each) \n",
      " Salt and pepper \n",
      " 12 ounces sauteed spinach \n",
      " 1 red pepper, roasted, peeled and quartered \n",
      " 12 ounces goat cheese \n",
      " 8 ounces Parmesan \n",
      " 4 teaspoons chopped Italian parsley \n",
      " 6 ounces flour \n",
      " 2 eggs \n",
      " 1/2 cup milk \n",
      " Bread crumbs \n",
      " 4 ounces Romano \n",
      " 2 teaspoons granulated garlic \n",
      " 6 ounces olive oil \n",
      "  \n",
      " Instructions: \n",
      " Make 1. Stir together chicken and saute. In a large bowl, beat together the bread crumbs and milk. Mix in the flour and egg mixture. In a large bowl, whisk together the Parmesan. Bring to a boil and cook for 30 minutes, or until just beginning to soften.  <|endoftext|> \n",
      " Ingredients: \n",
      " One 2-pound bag frozen potato nuggets, such as Tater Tots \n",
      " 3 cups shredded Cheddar \n",
      " 8 ounces cooked chorizo, crumbled \n",
      " 1 cup salsa \n",
      " 1/2 cup sliced pickled jalapenos \n",
      " 1/2 cup sour cream, thinned with a few tablespoons of water \n",
      " 1/4 cup diced red onion \n",
      " Coarsely chopped fresh cilantro, for sprinkling \n",
      "  \n",
      " Instructions: \n",
      " Melt the potato nuggets in a large saucepan over medium heat, whisking occasionally to coat. Add the potatoes. Stir together the chorizo, sour cream, red onion and pickled jalapenos. Bring the mixture to a boil. Drain the potato and season the skillet with salt and pepper. Bring to a boil. Cover the skillet with plastic wrap and preheat to 350 degrees F. Sprinkle the remaining 2 1/2 cups shredded Cheddar over the potatoes, chorizo, and pickled jalapenos on top. Cover the skillet with plastic wrap and preheat to 350 degrees F. Sprinkle the remaining 2 1/2 cups shredded Cheddar over the potato, chorizo, and pickled jalapenos. <|endoftext|> \n",
      " Ingredients: \n",
      " 1 small bunch of kale, stems removed, cut or torn into small pieces \n",
      " 1/4 cup pecans, toasted and chopped \n",
      " 1 green onion, chopped \n",
      " 1 pear, peeled and sliced \n",
      " Kosher salt and freshly ground black pepper \n",
      " 2 tablespoons balsamic vinegar \n",
      " 3 tablespoons extra-virgin olive oil \n",
      " Crumbled blue cheese, for garnish \n",
      "  \n",
      " Instructions: \n",
      " In a small bowl, cream together the kale. Heat the oil in a large skillet over medium heat; cook the kale in the oil. Pour the oil over the potatoes until they brown. Remove from oil and set aside. In a large bowl, whisk together the carrots, and peas. Season with salt, pepper, and black pepper. Add all the vegetables and mix well. Mix well. <|endoftext|> \n",
      " Ingredients: \n",
      " 2 tablespoons molasses \n",
      " 12 jalapenos \n",
      " 1/4 cup shredded mozzarella \n",
      " 1/3 cup cream cheese, room temperature \n",
      " 1/4 cup ricotta \n",
      " 3 tablespoons chopped shallots \n",
      " 1/3 cup diced cooked bacon \n",
      " 12 slices prosciutto \n",
      " 1 1/4 cups granulated sugar \n",
      " 1 cup cabernet sauvignon (recommended: Guardian Cellars) \n",
      " 1 (12-ounce) bag cranberries \n",
      " 1 tangerine, zested \n",
      " 1 whole cinnamon stick \n",
      "  \n",
      " Instructions: \n",
      " Fill a 9x13-inch baking dish with the molasses and jalapenos, then stir in the cream cheese, cranberries, and cream cheese. Bake in the preheated oven 30 minutes, covered and covered for a few hours. Serve at room temperature or as a sandwich. <|endoftext|> \n",
      " Ingredients: \n",
      " 1 cup unsalted roasted peanuts \n",
      " 1 cup chopped pecans \n",
      " 4 tablespoons shredded coconut (either fresh or the unsweetened desiccated kind) \n",
      " 2 tablespoons vegetable oil \n",
      " 1 tablespoon ground coriander \n",
      " 1 tablespoon ground cumin \n",
      " 2 teaspoons garam masala, store-bought or homemade, recipe follows \n",
      " 2 teaspoons kosher salt \n",
      " 1/4 cup green cardamom pods, shelled, husks discarded (about 2 tablespoons of seeds) \n",
      " 3 tablespoons whole cloves \n",
      " 4 large black cardamom pods, shelled, husks discarded (about 1 tablespoon of seeds), optional \n",
      " 3 large cinnamon sticks (if you have the kind you get at Indian stores, it's about 3 tablespoons of cinnamon bark bits) \n",
      "  \n",
      " Instructions: \n",
      " Preheat oven to 350 degrees F (200 degrees C) and line baking sheet with parchment paper. Arrange the roasted peanuts in 1\" baking dish; spread them evenly into baking sheets. In a large bowl, beat in cinnamon sticks. Whisk together the peanuts, cinnamon sticks, green cardamom pods, coriander, cinnamon stick, and cinnamon stick and beat in a separate bowl until combined. In a separate bowl, stir in garlic and ginger, 1/2 cup each mixture. Divide the mixture between the prepared baking dish and the prepared baking dish. In a saucepan, bring to a boil, reduce heat to medium-low, and simmer for 20 minutes. Remove from heat and cover the oven. Preheat oven to 350 degrees F (200 degrees C) and line baking sheet with parchment paper. Arrange the roasted peanuts in 1\" baking dish; spread them evenly into baking sheets. In a separate bowl, beat in cinnamon sticks. Whisk together the peanuts, cinnamon sticks, green cardamom pods, coriander, cinnamon stick, and cinnamon stick and beat in a separate bowl until combined. In a separate bowl, stir in garlic and ginger, 1/8 teaspoon each mixture. Divide the mixture between the prepared baking dish and the prepared baking dish. In a saucepan, bring to a boil, reduce heat to medium-low, and simmer for 20 minutes. Remove from heat and cover the oven. <|endoftext|> \n",
      " Ingredients: \n",
      " 3/4 cup coarse dry bread crumbs (preferably from a crusty loaf of Italian bread) \n",
      " 1 large garlic clove, minced \n",
      " 2 tablespoons minced drained bottled roasted peppers \n",
      " 2 tablespoons extra-virgin olive oil \n",
      " 1 tablespoon minced fresh oregano leaves or 3/4 teaspoon dried oregano, crumbled \n",
      " 24 small hard-shelled clams such as littlenecks, shucked, reserving 24 half shells \n",
      " Coarse sea or kosher salt for filling baking pan and serving platter. \n",
      "  \n",
      " Instructions: \n",
      " Mix bread crumbs and butter together in a small bowl. Mix bread crumbs and butter together in a small bowl. Place bread crumbs and butter together in a small bowl. Place bread crumbs and butter together in a small bowl. Place bread crumbs and butter together in a small bowl. Place bread crumbs and butter together in a small bowl. <|endoftext|> \n",
      " Ingredients: \n",
      " 1 box vanilla cake mix \n",
      " 1 small box vanilla pudding mix \n",
      " 1 cup buttermilk \n",
      " 1/2 cup vegetable oil \n",
      " 3 eggs \n",
      " Zest of 1 lemon \n",
      " Juice of 1/2 lemon \n",
      " Juice of 1/2 lime \n",
      " 2 cups powdered sugar \n",
      " 1 stick unsalted butter \n",
      " 1/4 cup buttermilk \n",
      " Zest of 1 lemon \n",
      " Zest of 1 lime \n",
      " Juice of 1/2 lemon \n",
      "  \n",
      " Instructions: \n",
      " Preheat oven to 350 degrees F (175 degrees C). Line a baking sheet with parchment paper. Line a baking sheet with parchment paper and place the dough on a baking sheet. Bake for 8 to 9 minutes, then roll out the dough onto a floured surface. Remove from oven and cool completely. Place the cake mix on a lightly floured cookie sheet. Bake until golden brown, about 15 minutes. Cool completely. Place the cake mixture on a lightly floured cookie sheet. Cool slightly. Place a layer on the center of the cake mixture, about 4 inches from the edges of the cake. Place each layer on the surface of the cake mixture. Repeat layer on the other side of the cake mixture. Bake until cake is lightly browned on both sides, about 25 minutes. Cool completely before serving.  <|endoftext|> \n",
      " Ingredients: \n",
      " 6 hard boiled eggs \n",
      " 1 stalk celery, finely diced \n",
      " 1/2 red bell pepper, seeded and finely diced \n",
      " 1 heaping teaspoon Dijon mustard \n",
      " 1/4 cup mayonnaise \n",
      " 2 cloves roasted garlic \n",
      " 2 teaspoons curry powder \n",
      " Salt and pepper, to taste \n",
      " 1 ciabatta, sliced in thirds and halved \n",
      "  \n",
      " Instructions: \n",
      " Preheat oven to 350 degrees F (175 degrees C). Lightly grease a 9x13 inch baking dish. Grease with a toothpick. Bake in the preheated oven until golden brown and bubbly, about 30 minutes. <|endoftext|> \n",
      " Ingredients: \n",
      " 3 large eggs \n",
      " 4 tablespoons unsalted butter \n",
      " Pinch kosher salt \n",
      " Fresh chives, for garnish \n",
      " Extra-virgin olive oil, for drizzling \n",
      " Serving suggestion: Serve with roasted tomatoes and peasant bread. \n",
      "  \n",
      " Instructions: \n",
      " Preheat oven to 350Â°F. Grease a 9x4\" glass baking dish with parchment paper. Whisk together butter and butter in a mixing bowl. Stir together eggs, chives, and pinch kosher salt in a small bowl. Stir together chives, chives, and pinch kosher salt in a small bowl. Stir together chives, and pinch kosher salt in a small bowl. <|endoftext|> \n",
      " Ingredients: \n",
      " 1 tablespoon coconut oil \n",
      " 12 ounces small string beans, stems removed and beans cut in half \n",
      " Kosher salt and coarsely ground black pepper \n",
      " 3 tablespoons mango chutney \n",
      "  \n",
      " Instructions: \n",
      " Preheat oven to 350 degrees F (175 degrees C). Grease a 9x9x13 inch baking dish. Place bean in a 9x8 inch baking dish. Spread beans evenly on top of each bean. Bake until beans have softened, about 20 minutes to overnight. Cool. Combine all ingredients in the prepared baking dish. Pour beans evenly over and serve.  <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(AllRecipes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
