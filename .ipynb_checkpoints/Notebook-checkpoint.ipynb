{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining Group Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#https://eightportions.com/datasets/Recipes/#fn:1 where the data is from\n",
    "#scraped from \n",
    "#Foodnetwork.com, Epicurious.com, Allrecipes.com by someone\n",
    "\n",
    "allr = open('recipes_raw_nosource_ar.json')\n",
    "epi = open('recipes_raw_nosource_epi.json')\n",
    "food = open('recipes_raw_nosource_fn.json')\n",
    "\n",
    "data1 = json.load(allr) #data 1 has a lot of the word ADVERTISEMENT\n",
    "data2 = json.load(epi) #data 2 looks good\n",
    "data3 = json.load(food) #this too\n",
    "\n",
    "#this load module loads the data into a dictionary \n",
    "\n",
    "for key, value in data3.items():\n",
    "    print(value)\n",
    "#example of a specific recipe with a certain key and the value is also a dictionary\n",
    "print(data3[\"p3pKOD6jIHEcjf20CCXohP8uqkG5dGi\"])\n",
    "\n",
    "#example of only instructions\n",
    "print(data3[\"p3pKOD6jIHEcjf20CCXohP8uqkG5dGi\"]['instructions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammie Hamblet's Deviled Crab\n"
     ]
    }
   ],
   "source": [
    "print(data3[\"p3pKOD6jIHEcjf20CCXohP8uqkG5dGi\"]['title'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative idea: maybe make model input a list of ingredients (based on what you have at home), and then let the model generate a reicpe for you based on the ingredients you have available\n",
    "\n",
    "if that is the route we take, we can alternatively make another function that generates random lists of ingredients, and then feed the random ingredients to the recipe maker based on ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part, we really have to look at getting all of the recipes into the same format: so the model will learn to recognize the format, and start to use it.\n",
    "\n",
    "Our current recipes are in a dict of list of dict form, where the first dict contains the recipe code as key and the recipe as value, and the recipe value itself is a list of dicts in the shape [{instructions: value}, {ingredients: value}, {instructions:value}, {title:value}]. We start by transforming this into a more comprehensible and workable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some help from: [TowardsDataScience](https://towardsdatascience.com/text-generation-with-python-and-gpt-2-1fecbff1635b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence\n",
    "Here we define an arbitrary recipe string sequence to initially train and test our model with. This text will be improved when we have acquired some data, but this will do for initial development:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'placeholder'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"\"\"Ingredients: 3 tomatoes, garlic, spaghetti, Spanish chili's, cheese. Boil the pasta, then rinse. Cut chili's and mince garlic, add to pan\n",
    "Add tomatoes and the pasta, and grate a generous amount of cheese\n",
    "Serve with a touch of basil and a glass of good red wine\n",
    "           \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Allemaal van Sergio\n",
    "\n",
    "\"\"\"\n",
    "seqdata = []\n",
    "print(len(data3.keys()))\n",
    "count = 0\n",
    "for key, value in data3.items():\n",
    "    check = False\n",
    "    \n",
    "    #check whether it has the key ingredients\n",
    "    if \"ingredients\" in value.keys():\n",
    "        check = True\n",
    "    \n",
    "    #amount of recipes you want\n",
    "    if count <= 800 and check:\n",
    "        count = count +1\n",
    "        listingr = \"ingredients: \"\n",
    "        for i in value[\"ingredients\"]:\n",
    "            listingr = listingr + i + \" \"\n",
    "        if type(value[\"instructions\"]) == str:\n",
    "            r = listingr + value[\"instructions\"]\n",
    "            seqdata.append(r)\n",
    "            continue\n",
    "\n",
    "print(type(seqdata))\n",
    "#first two recipes\n",
    "print(seqdata[2])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"placeholder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the pretrained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT2's development can be found at: Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2018). Language Models are Unsupervised Multitask Learners. 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'placeholder'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenizing the inputs\n",
    "#print(seqdata[1])\n",
    "inputs = tokenizer.encode(sequence, return_tensors='pt')\n",
    "#print(inputs)\n",
    "\n",
    "\n",
    "\n",
    "#Allemaal van Sergio\n",
    "\n",
    "\"\"\"\n",
    "tokenizer.pad_token = \"tokenizer.eos_token\"\n",
    "#padding and truncation to make all tensors same size.\n",
    "#encoded_choices = [tokenizer.encode(s) for s in seqdata]\n",
    "input_ids = []\n",
    "\n",
    "for i in seqdata:\n",
    "    input_ids.append(tokenizer.encode(i, return_tensors='pt', padding=True,truncation = True))\n",
    "\n",
    "print(input_ids) #input Ids is now list with tensors of each datapoint\n",
    "\n",
    "\"\"\"\n",
    "'placeholder'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate a recipe based on the encoded cooking texts that we fed the model above. We will use the model.generate() function to do this.\n",
    "Model.generate() has a lot of different variable options worth looking at, which can be used to optimize our model. For instance, the temperature variable can be tweaked between 0-5 for increased randomness, we can try no_repeat_ngram_size=2 to prevent repitition, or tweak top_k. We'll just have to play around a bit and see what works best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#this only works only when you pick a specific tensor of input ids and not for all\\nEncodedRecipe2 = model.generate(input_ids[2], max_length=1024, do_sample=True)\\nprint(EncodedRecipe2)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# We set the output length to 500 tokens\n",
    "EncodedRecipe = model.generate(inputs, max_length=500, do_sample=True)\n",
    "\n",
    "\n",
    "\n",
    "#Allemaal van Sergio\n",
    "\"\"\"\n",
    "#this only works only when you pick a specific tensor of input ids and not for all\n",
    "EncodedRecipe2 = model.generate(input_ids[2], max_length=1024, do_sample=True)\n",
    "print(EncodedRecipe2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2054\n",
      "Ingredients: 3 tomatoes, garlic, spaghetti, Spanish chili's, cheese. Boil the pasta, then rinse. Cut chili's and mince garlic, add to pan\n",
      "Add tomatoes and the pasta, and grate a generous amount of cheese\n",
      "Serve with a touch of basil and a glass of good red wine\n",
      "              Recipe Author: Tom Jones\n",
      "\n",
      "Servings : 6 Prep Time : 6 hours. 3 people Prep Time : 30 hours. 5 minutes per person. Yield : 6 servings Ingredients: 3 tomatoes, garlic, spaghetti, Spanish chili's, cheese. Boil the pasta, then drain. Cut chili's and mince garlic, add to pan Add tomatoes and the pasta, and grate a generous amount of cheese Save Recipe Print Ingredients for the Caesar and Basil Sauce: 1 large red bell pepper, chopped\n",
      "\n",
      "1 clove garlic\n",
      "\n",
      "1/2 tsp. dried basil\n",
      "\n",
      "1 tsp. red pepper flakes\n",
      "\n",
      "1 Tsp. coriander\n",
      "\n",
      "1 tsp. sesame seeds\n",
      "\n",
      "1 tsp. cayenne pepper\n",
      "\n",
      "1 pinch salt\n",
      "\n",
      "1 Tsp. ground cayenne pepper Instructions Sauté the garlic, basil, red pepper flakes, cayenne pepper, and salt in a bowl. Mix the herbs and garlic until well combined. Add the tomatoes and the garlic powder until combined. Add the red pepper flakes and sesame seeds until well mixed. Add the chili paste and cook for about 2 minutes\n",
      "\n",
      "Place the pasta ingredients all on the sheet in a plate. Toss well with the hot sauce and leave 1 cup to simmer. When the pasta is ready, heat a medium sized food processor. Process one or 2 cups of the pasta until pasta is thoroughly mixed. If using extra large plates, place in an airtight container to keep them moist. Toss in the red pepper flakes then stir to combine, stirring well to combine the food processor and pasta. Season the sauce to taste. Adjust the seasoning using a spoon. Serve. Notes 1. We do not recommend removing the meat when using the pasta. It can result in a bit of heat. Please note that while cooked it may not cook quickly, so be VERY sure the pasta is very well cleaned! **You can also add a tablespoon of ground cayenne pepper or just a pinch of minced red pepper flakes to the sauce. Serve with a small glass of wine! Nutrition information\n"
     ]
    }
   ],
   "source": [
    "#Decode the tokenized outputs\n",
    "#recipe = tokenizer.decode(EncodedRecipe[0], skip_special_tokens=True)\n",
    "#We filter out the initial context sequence given to the model (258 characters)\n",
    "#print(recipe[259:])\n",
    "\n",
    "#Decode the tokenized outputs\n",
    "recipe = tokenizer.decode(EncodedRecipe[0], skip_special_tokens=True)\n",
    "#We filter out the initial context sequence given to the model (258 characters)\n",
    "print(len(recipe))\n",
    "print(recipe) #part of it original and part of it the same as before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this repetition in this recipe is a great example of why we may have to try ways to prevent repetition in the model generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save generated recipes as .txt files:\n",
    "def save(recipe, filename):\n",
    "    text_file = open(filename, \"w\", encoding = 'utf8')\n",
    "    n = text_file.write(recipe)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the previously generated recipe:\n",
    "save(recipe[259:], 'FirstRecipe.txt')\n",
    "#Note: I am leaving out the 259 context characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement learning\n",
    "I had some inspiration for a potentially novel approach to take this model in: reinforcement learning. While the current model already performs relatively well on creating sensical recipe texts, the model still has absolutely no idea of 'taste', and which ingredients work well together and which don't. Therefore, it may be desireable to give the model some sort of loss function score on its recipes so it knows which recipes are good and which are bad, so the model can improve.\n",
    "We could do this by either reading the recipes and rating them on how good we think they might be, or maybe even try to cook some of the things our model suggests and see how well they work, so we can help the model improve. While this may take some time and make the coding harder, it could be really cool to have a recipe generation model trained and optimized on actual real-world cooking, and I can hardly imagine anyone has ever done something like that before. Who knows, maybe the model will actually end up becoming a really good cook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contributors: Emilia, Sergio, Tim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
