{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining Group Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't forget to 'pip install tranformers, pip install torch' in conda prompt\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part, we really have to look at getting all of the recipes into the same format: so the model will learn to recognize the format, and start to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some help from: [TowardsDataScience](https://towardsdatascience.com/text-generation-with-python-and-gpt-2-1fecbff1635b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence\n",
    "Here we define an arbitrary recipe string sequence to initially train and test our model with. This text will be improved when we have acquired some data, but this will do for initial development:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"\"\"Ingredients: 3 tomatoes, garlic, spaghetti, Spanish chili's, cheese. Boil the pasta, then rinse. Cut chili's and mince garlic, add to pan\n",
    "Add tomatoes and the pasta, and grate a generous amount of cheese\n",
    "Serve with a touch of basil and a glass of good red wine\n",
    "           \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the pretrained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT2's development can be found at: Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2018). Language Models are Unsupervised Multitask Learners. 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing the inputs\n",
    "inputs = tokenizer.encode(sequence, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate a recipe based on the encoded cooking texts that we fed the model above. We will use the model.generate() function to do this.\n",
    "Model.generate() has a lot of different variable options worth looking at, which can be used to optimize our model. For instance, the temperature variable can be tweaked between 0-5 for increased randomness, we can try no_repeat_ngram_size=2 to prevent repitition, or tweak top_k. We'll just have to play around a bit and see what works best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# We set the output length to 500 tokens\n",
    "EncodedRecipe = model.generate(inputs, max_length=500, do_sample=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           \n",
      "Serve in a glass or glass jar\n",
      "Serving Size 1 pizza box, 4 1⁄2 cups (about 2 medium-sized pizzas) (approx 2 1⁄4 cups each) Prep time 15 minutes Cook time 20 minutes Total time 30 minutes Ingredients 2 cups (about 2 medium-sized pizzas) fresh mozzarella, finely chopped (about 1 tablespoon each of the 2 tablespoons) Italian seasoning (I add 2 teaspoons to this recipe for a little salt) (use 3 or 4 minced eggs for flavor) 3/4 cup (about 1 medium-sized pizza) chopped tomatoes, diced. Place in medium heat and add the tomatoes, 2 cups water and 2 tablespoons olive oil, plus a pinch for salt, for about 3 hours Cook on medium-low until sauce is brown\n",
      "Serve as a side and serve in 3 or 4 bowls, or just before\n",
      "Serve piping hot as you like\n",
      "Yield: Ingredients 2 cups (about 2 medium-sized pizzas, 4 1⁄2 cups each) pizzas Serving size 1 pizza box, 1 1⁄2 cups (about 2 medium-sized pizzas) (approx 2 1⁄4 cups each) Prep time 15 minutes Cook time 20 minutes Total time 30 minutes Ingredients 6 large non-grit cheese ramekins, chopped Instructions Combine all of 3 ingredients in a separate large saucepan over medium heat. Whisk well. Stir and turn the mixture when bubbling a few times to stir. Pour into bowl and add any sauce you like. Stir over slow simmering for 15 minutes. Add remaining 1/4 cup hot 2 tablespoons olive oil to the mixture. Use a spatula to gently swirl mixture around pizzater grater\n",
      "Cover and freeze on cookie sheets for up to 3 days. Nutrition Facts Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade Homemade\n"
     ]
    }
   ],
   "source": [
    "#Decode the tokenized outputs\n",
    "recipe = tokenizer.decode(EncodedRecipe[0], skip_special_tokens=True)\n",
    "#We filter out the initial context sequence given to the model (258 characters)\n",
    "print(recipe[259:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this repetition of Homemade Homemade Homemade at the end of the recipe is a great example of why we may have to try ways to prevent repetition in the model generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contributors: Emilia, Sergio, Tim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
